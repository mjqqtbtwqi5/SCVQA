{"cells":[{"cell_type":"markdown","metadata":{"id":"uRXpIJ0q6d1J"},"source":["# Mount Google Drive"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"NR2PT9Ya0InI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713020380398,"user_tz":-480,"elapsed":2993,"user":{"displayName":"Yingqi CHEN","userId":"09344060353484671500"}},"outputId":"b4441f10-8ace-4242-d3eb-681428d336d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"wNxdwvmP6iLD"},"source":["# Append project path"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"2r3bOPsO6h_K","executionInfo":{"status":"ok","timestamp":1713020380398,"user_tz":-480,"elapsed":23,"user":{"displayName":"Yingqi CHEN","userId":"09344060353484671500"}}},"outputs":[],"source":["import sys\n","\n","PROJECT_PATH_UTIL = \"/content/drive/MyDrive/Colab Notebooks/SCVQA/util\"\n","#                    /content/drive/MyDrive/.../util\n","sys.path.append(PROJECT_PATH_UTIL)"]},{"cell_type":"markdown","metadata":{"id":"G3EidBIl6r2A"},"source":["# Import libraries and py script coded"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Ao2BfgxX67XI","executionInfo":{"status":"ok","timestamp":1713020380398,"user_tz":-480,"elapsed":22,"user":{"displayName":"Yingqi CHEN","userId":"09344060353484671500"}}},"outputs":[],"source":["import torch\n","from torch import nn\n","\n","import os\n","import random\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","\n","from model import LSTM, Transformer"]},{"cell_type":"markdown","metadata":{"id":"m8M9SrxioC98"},"source":["# Custom function"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"kcySwzhOoCkI","executionInfo":{"status":"ok","timestamp":1713020380398,"user_tz":-480,"elapsed":21,"user":{"displayName":"Yingqi CHEN","userId":"09344060353484671500"}}},"outputs":[],"source":["def up_scale(score_predicted: float, mos_max: float, mos_min: float):\n","  return score_predicted * (mos_max - mos_min) + mos_min"]},{"cell_type":"markdown","metadata":{"id":"MMBiBWgb7NwO"},"source":["# Setup parameters"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Hq9HOS2V7NIm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713020380398,"user_tz":-480,"elapsed":21,"user":{"displayName":"Yingqi CHEN","userId":"09344060353484671500"}},"outputId":"a87c562a-e3dd-44fd-a048-75bb86cf58b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Transformer-based] | database: CSCVQ, CNN extraction: ResNet50, device: cuda\n"]}],"source":["_LSTM = \"LSTM\"\n","_TRANSFORMER = \"Transformer\"\n","\n","_CSCVQ = \"CSCVQ\"\n","_SCVD = \"SCVD\"\n","\n","_ResNet18 = \"ResNet18\"\n","_ResNet34 = \"ResNet34\"\n","_ResNet50 = \"ResNet50\"\n","_ResNet101 = \"ResNet101\"\n","_ResNet34_ResNet50 = \"ResNet34_ResNet50\"\n","\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","#===============================================================================\n","\n","# Instance\n","MODEL = _TRANSFORMER          # Model Architecture Approach\n","DATABASE = _CSCVQ             # Database\n","CNN_EXTRACTION = _ResNet50    # Extractor\n","\n","# Input video\n","VIDEO_NAME = \"sc_ChromeBrowsing_1280x720_30_8bit_420_300f_264QP48.yuv\"\n","\n","#===============================================================================\n","\n","\n","\n","FEATURE_DIR = Path(f\"/content/drive/MyDrive/Colab Notebooks/SCVQA/feature/{DATABASE}/{CNN_EXTRACTION}/\")\n","#                   /content/drive/MyDrive/.../feature/{DATABASE}/{CNN_EXTRACTION}/\n","\n","MODEL_DIR = Path(f\"/content/drive/MyDrive/Colab Notebooks/SCVQA/model/{MODEL}/{DATABASE}/{CNN_EXTRACTION}/\")\n","#                  /content/drive/MyDrive/.../model/{MODEL}/{DATABASE}/{CNN_EXTRACTION}/\n","\n","MODEL_DIR_HIST_FILE = Path(f\"/content/drive/MyDrive/Colab Notebooks/SCVQA/model/{MODEL}/{DATABASE}/{CNN_EXTRACTION}/history.csv\")\n","#                            /content/drive/MyDrive/.../model/{MODEL}/{DATABASE}/{CNN_EXTRACTION}/history.csv\n","\n","\n","MOS_MIN, MOS_MAX = (20.1179, 74.0773) if DATABASE == _SCVD else (20.53108285, 72.75596394)\n","\n","\n","print(\n","    f\"[{MODEL}-based] | database: {DATABASE}, CNN extraction: {CNN_EXTRACTION}, device: {DEVICE}\"\n",")"]},{"cell_type":"markdown","metadata":{"id":"KnoXLGKJ7rqi"},"source":["# Read input video data"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"pnlqpFH379k5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713020380399,"user_tz":-480,"elapsed":21,"user":{"displayName":"Yingqi CHEN","userId":"09344060353484671500"}},"outputId":"812da8a0-c9f5-40be-f2bd-65ed380538f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Read sc_ChromeBrowsing_1280x720_30_8bit_420_300f_264QP48.yuv from CSCVQ\n"]}],"source":["input_video_file = f\"{FEATURE_DIR}/{VIDEO_NAME}/feature.npy\"\n","\n","input_video = np.load(input_video_file)\n","input_video = torch.from_numpy(input_video)\n","\n","print(\n","    f\"Read {VIDEO_NAME} from {DATABASE}\"\n",")"]},{"cell_type":"markdown","metadata":{"id":"qsfPOm8M8DbY"},"source":["# Inference"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"BcmFrV918DMT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2bbc8474-d005-48f4-9102-2a563539c2af","executionInfo":{"status":"ok","timestamp":1713020380399,"user_tz":-480,"elapsed":20,"user":{"displayName":"Yingqi CHEN","userId":"09344060353484671500"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Load model from /content/drive/MyDrive/Colab Notebooks/SCVQA/model/Transformer/CSCVQ/ResNet50/20240321_172018/model.pt\n","\n","Result\n","Model: Transformer-based\n","Database: CSCVQ\n","Extractor: ResNet50\n","\n","Video: sc_ChromeBrowsing_1280x720_30_8bit_420_300f_264QP48.yuv\n","Predict score: 60.35\n"]}],"source":["feature_size = None\n","if CNN_EXTRACTION == _ResNet18 or CNN_EXTRACTION == _ResNet34:\n","    feature_size = 1024\n","elif CNN_EXTRACTION == _ResNet50 or CNN_EXTRACTION == _ResNet101:\n","    feature_size = 4096\n","else:\n","    feature_size = 5120\n","\n","model = None\n","if MODEL == _LSTM:\n","    model = LSTM(\n","        device=DEVICE,\n","        feature_size=feature_size,\n","    ).to(device=DEVICE)\n","elif MODEL == _TRANSFORMER:\n","    model = Transformer(\n","        device=DEVICE,\n","        feature_size=feature_size,\n","    ).to(device=DEVICE)\n","\n","if os.path.exists(MODEL_DIR_HIST_FILE):\n","    hist_df = pd.read_csv(MODEL_DIR_HIST_FILE)\n","    model_file = Path(MODEL_DIR / hist_df[\"DIR\"].iloc[-1] / \"model.pt\")\n","    if os.path.exists(model_file):\n","        print(f\"Load model from {model_file}\")\n","        model.load_state_dict(torch.load(f=str(model_file)))\n","\n","score_predicted = None\n","\n","model.eval()\n","with torch.inference_mode():\n","\n","  input = input_video.to(device=DEVICE)\n","  input = input.unsqueeze(dim=0)\n","\n","  score_predicted = model(input).item()\n","  score_predicted = up_scale(score_predicted, MOS_MIN, MOS_MAX)\n","\n","#Summary\n","print()\n","print(\"Result\")\n","print(f\"Model: {MODEL}-based\")\n","print(f\"Database: {DATABASE}\")\n","print(f\"Extractor: {CNN_EXTRACTION}\")\n","print()\n","print(f\"Video: {VIDEO_NAME}\")\n","print(f\"Predict score: {round(score_predicted, 2)}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"V100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyOVjanKH9G083nEXfGRq6+4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}